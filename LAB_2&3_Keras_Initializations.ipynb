{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras-Initializations.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reubence/Deep-Learning/blob/master/LAB_2%263_Keras_Initializations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7HfTHNo-aXK",
        "colab_type": "text"
      },
      "source": [
        "#Usage of initializers\n",
        "\n",
        "Initializations define the way to set the initial random weights of Keras layers.\n",
        "\n",
        "The keyword arguments used for passing initializers to layers will depend on the layer. Usually it is simply kernel_initializer and bias_initializer:\n",
        "\n",
        "Lets test the various initializations of weights on our baseline model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8WJIsdG_Sz_",
        "colab_type": "text"
      },
      "source": [
        "# Baseline model for classification on CIFAR10 dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09sdc-v8-HTt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import packages\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "#import dataset\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "#change shape from image to vector\n",
        "X_train = X_train.reshape(50000, 32 * 32 * 3)\n",
        "X_test = X_test.reshape(10000, 32 * 32 * 3)\n",
        "\n",
        "#preprocess\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255.0\n",
        "X_test /= 255.0\n",
        "\n",
        "#change labels from numeric to one hot encoded\n",
        "Y_train = to_categorical(y_train, 10)\n",
        "Y_test =  to_categorical(y_test, 10)\n",
        "\n",
        "#Model building\n",
        "model = Sequential()\n",
        "model.add(Dense(1024, input_shape=(3072, )))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        " \n",
        "\n",
        "# training\n",
        "history = model.fit(X_train, Y_train,\n",
        "                        batch_size=128,\n",
        "                        nb_epoch=5,\n",
        "                        verbose=1,\n",
        "                        validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymoVRayJ_v1V",
        "colab_type": "text"
      },
      "source": [
        "# Model with Initializer as random uniform and zero"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LavTm0MQ_6ZO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import packages\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "#import dataset\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "#change shape from image to vector\n",
        "X_train = X_train.reshape(50000, 32 * 32 * 3)\n",
        "X_test = X_test.reshape(10000, 32 * 32 * 3)\n",
        "\n",
        "#preprocess\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255.0\n",
        "X_test /= 255.0\n",
        "\n",
        "#change labels from numeric to one hot encoded\n",
        "Y_train = to_categorical(y_train, 10)\n",
        "Y_test =  to_categorical(y_test, 10)\n",
        "\n",
        "#Model building\n",
        "model = Sequential()\n",
        "model.add(Dense(1024, input_shape=(3072,), kernel_initializer='random_uniform', bias_initializer='zeros'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512, kernel_initializer='random_uniform', bias_initializer='zeros'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512, kernel_initializer='random_uniform', bias_initializer='zeros'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(10, kernel_initializer='random_uniform', bias_initializer='zeros'))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        " \n",
        "\n",
        "# training\n",
        "history = model.fit(X_train, Y_train,\n",
        "                        batch_size=128,\n",
        "                        nb_epoch=5,\n",
        "                        verbose=1,\n",
        "                        validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysqToiwvBVae",
        "colab_type": "text"
      },
      "source": [
        "#Model with weights as ones"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hy37WX9Bm3x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import packages\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "#import dataset\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "#change shape from image to vector\n",
        "X_train = X_train.reshape(50000, 32 * 32 * 3)\n",
        "X_test = X_test.reshape(10000, 32 * 32 * 3)\n",
        "\n",
        "#preprocess\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255.0\n",
        "X_test /= 255.0\n",
        "\n",
        "#change labels from numeric to one hot encoded\n",
        "Y_train = to_categorical(y_train, 10)\n",
        "Y_test =  to_categorical(y_test, 10)\n",
        "\n",
        "#Model building\n",
        "model = Sequential()\n",
        "model.add(Dense(1024, input_shape=(3072,), kernel_initializer='ones', bias_initializer='ones'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512, kernel_initializer='ones', bias_initializer='ones'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512, kernel_initializer='ones', bias_initializer='ones'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(10, kernel_initializer='ones', bias_initializer='ones'))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        " \n",
        "\n",
        "# training\n",
        "history = model.fit(X_train, Y_train,\n",
        "                        batch_size=128,\n",
        "                        nb_epoch=5,\n",
        "                        verbose=1,\n",
        "                        validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wt4hjq_eCFyu",
        "colab_type": "text"
      },
      "source": [
        "# Model initialized with constant values\n",
        "\n",
        "Initializer that generates tensors initialized to a constant value.\n",
        "\n",
        "Arguments\n",
        "\n",
        "1. value: float; the value of the generator tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLAIW3w0COQV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import packages\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "#import dataset\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "#change shape from image to vector\n",
        "X_train = X_train.reshape(50000, 32 * 32 * 3)\n",
        "X_test = X_test.reshape(10000, 32 * 32 * 3)\n",
        "\n",
        "#preprocess\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255.0\n",
        "X_test /= 255.0\n",
        "\n",
        "#change labels from numeric to one hot encoded\n",
        "Y_train = to_categorical(y_train, 10)\n",
        "Y_test =  to_categorical(y_test, 10)\n",
        "\n",
        "#Model building\n",
        "initializer = keras.initializers.Constant(value=0)\n",
        "model = Sequential()\n",
        "model.add(Dense(1024, input_shape=(3072,), kernel_initializer=initializer, bias_initializer=initializer))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512, kernel_initializer=initializer, bias_initializer=initializer))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512, kernel_initializer=initializer, bias_initializer=initializer))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(10, kernel_initializer=initializer, bias_initializer=initializer))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        " \n",
        "\n",
        "# training\n",
        "history = model.fit(X_train, Y_train,\n",
        "                        batch_size=128,\n",
        "                        nb_epoch=5,\n",
        "                        verbose=1,\n",
        "                        validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sA0dnI8SCuBG",
        "colab_type": "text"
      },
      "source": [
        "#RandomNormal\n",
        "keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None)\n",
        "Initializer that generates tensors with a normal distribution.\n",
        "\n",
        "Arguments\n",
        "\n",
        "1. mean: a python scalar or a scalar tensor. Mean of the random values to generate.\n",
        "2. stddev: a python scalar or a scalar tensor. Standard deviation of the random values to generate.\n",
        "3. seed: A Python integer. Used to seed the random generator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hp1NkCnlDFIu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import packages\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "#import dataset\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "#change shape from image to vector\n",
        "X_train = X_train.reshape(50000, 32 * 32 * 3)\n",
        "X_test = X_test.reshape(10000, 32 * 32 * 3)\n",
        "\n",
        "#preprocess\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255.0\n",
        "X_test /= 255.0\n",
        "\n",
        "#change labels from numeric to one hot encoded\n",
        "Y_train = to_categorical(y_train, 10)\n",
        "Y_test =  to_categorical(y_test, 10)\n",
        "\n",
        "#Model building\n",
        "initializer = keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None)\n",
        "model = Sequential()\n",
        "model.add(Dense(1024, input_shape=(3072,), kernel_initializer=initializer, bias_initializer=initializer))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512, kernel_initializer=initializer, bias_initializer=initializer))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512, kernel_initializer=initializer, bias_initializer=initializer))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(10, kernel_initializer=initializer, bias_initializer=initializer))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        " \n",
        "\n",
        "# training\n",
        "history = model.fit(X_train, Y_train,\n",
        "                        batch_size=128,\n",
        "                        nb_epoch=5,\n",
        "                        verbose=1,\n",
        "                        validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3K_gczVbDMRC",
        "colab_type": "text"
      },
      "source": [
        "#RandomUniform\n",
        "keras.initializers.RandomUniform(minval=-0.05, maxval=0.05, seed=None)\n",
        "Initializer that generates tensors with a uniform distribution.\n",
        "\n",
        "Arguments\n",
        "\n",
        "1. minval: A python scalar or a scalar tensor. Lower bound of the range of random values to generate.\n",
        "2. maxval: A python scalar or a scalar tensor. Upper bound of the range of random values to generate. Defaults to 1 for float types.\n",
        "3. seed: A Python integer. Used to seed the random generator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MTNL18EDR8j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import packages\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "#import dataset\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "#change shape from image to vector\n",
        "X_train = X_train.reshape(50000, 32 * 32 * 3)\n",
        "X_test = X_test.reshape(10000, 32 * 32 * 3)\n",
        "\n",
        "#preprocess\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255.0\n",
        "X_test /= 255.0\n",
        "\n",
        "#change labels from numeric to one hot encoded\n",
        "Y_train = to_categorical(y_train, 10)\n",
        "Y_test =  to_categorical(y_test, 10)\n",
        "\n",
        "#Model building\n",
        "initializer = keras.initializers.RandomUniform(minval=-0.05, maxval=0.05, seed=None)\n",
        "model = Sequential()\n",
        "model.add(Dense(1024, input_shape=(3072,), kernel_initializer=initializer, bias_initializer=initializer))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512, kernel_initializer=initializer, bias_initializer=initializer))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512, kernel_initializer=initializer, bias_initializer=initializer))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(10, kernel_initializer=initializer, bias_initializer=initializer))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        " \n",
        "\n",
        "# training\n",
        "history = model.fit(X_train, Y_train,\n",
        "                        batch_size=128,\n",
        "                        nb_epoch=5,\n",
        "                        verbose=1,\n",
        "                        validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCx54MFWDgnj",
        "colab_type": "text"
      },
      "source": [
        "#TruncatedNormal\n",
        "keras.initializers.TruncatedNormal(mean=0.0, stddev=0.05, seed=None)\n",
        "Initializer that generates a truncated normal distribution.\n",
        "\n",
        "These values are similar to values from a RandomNormal except that values more than two standard deviations from the mean are discarded and redrawn. This is the recommended initializer for neural network weights and filters.\n",
        "\n",
        "Arguments\n",
        "\n",
        "1. mean: a python scalar or a scalar tensor. Mean of the random values to generate.\n",
        "2. stddev: a python scalar or a scalar tensor. Standard deviation of the random values to generate.\n",
        "3. seed: A Python integer. Used to seed the random generator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9ty4foYDmBj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import packages\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "#import dataset\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "#change shape from image to vector\n",
        "X_train = X_train.reshape(50000, 32 * 32 * 3)\n",
        "X_test = X_test.reshape(10000, 32 * 32 * 3)\n",
        "\n",
        "#preprocess\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255.0\n",
        "X_test /= 255.0\n",
        "\n",
        "#change labels from numeric to one hot encoded\n",
        "Y_train = to_categorical(y_train, 10)\n",
        "Y_test =  to_categorical(y_test, 10)\n",
        "\n",
        "#Model building\n",
        "initializer = keras.initializers.TruncatedNormal(mean=0.0, stddev=0.05, seed=None)\n",
        "model = Sequential()\n",
        "model.add(Dense(1024, input_shape=(3072,), kernel_initializer=initializer, bias_initializer=initializer))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512, kernel_initializer=initializer, bias_initializer=initializer))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512, kernel_initializer=initializer, bias_initializer=initializer))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(10, kernel_initializer=initializer, bias_initializer=initializer))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        " \n",
        "\n",
        "# training\n",
        "history = model.fit(X_train, Y_train,\n",
        "                        batch_size=128,\n",
        "                        nb_epoch=5,\n",
        "                        verbose=1,\n",
        "                        validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2LU6BByDtCE",
        "colab_type": "text"
      },
      "source": [
        "#VarianceScaling\n",
        "1. keras.initializers.VarianceScaling(scale=1.0, mode='fan_in', distribution='normal', seed=None)\n",
        "2. Initializer capable of adapting its scale to the shape of weights.\n",
        "\n",
        "With distribution=\"normal\", samples are drawn from a truncated normal distribution centered on zero, with stddev = sqrt(scale / n) where n is:\n",
        "\n",
        "1. number of input units in the weight tensor, if mode = \"fan_in\"\n",
        "2. number of output units, if mode = \"fan_out\"\n",
        "3. average of the numbers of input and output units, if mode = \"fan_avg\"\n",
        "\n",
        "With distribution=\"uniform\", samples are drawn from a uniform distribution within [-limit, limit], with limit = sqrt(3 * scale / n).\n",
        "\n",
        "Arguments\n",
        "\n",
        "1. scale: Scaling factor (positive float).\n",
        "2. mode: One of \"fan_in\", \"fan_out\", \"fan_avg\".\n",
        "3. distribution: Random distribution to use. One of \"normal\", \"uniform\".\n",
        "4. seed: A Python integer. Used to seed the random generator.\n",
        "\n",
        "Raises\n",
        "\n",
        "ValueError: In case of an invalid value for the \"scale\", mode\" or \"distribution\" arguments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7R-rDZuQD8Yd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import packages\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "#import dataset\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "#change shape from image to vector\n",
        "X_train = X_train.reshape(50000, 32 * 32 * 3)\n",
        "X_test = X_test.reshape(10000, 32 * 32 * 3)\n",
        "\n",
        "#preprocess\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255.0\n",
        "X_test /= 255.0\n",
        "\n",
        "#change labels from numeric to one hot encoded\n",
        "Y_train = to_categorical(y_train, 10)\n",
        "Y_test =  to_categorical(y_test, 10)\n",
        "\n",
        "#Model building\n",
        "initializer = keras.initializers.VarianceScaling(scale=1.0, mode='fan_in', distribution='normal', seed=None)\n",
        "model = Sequential()\n",
        "model.add(Dense(1024, input_shape=(3072,), kernel_initializer=initializer, bias_initializer=initializer))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512, kernel_initializer=initializer, bias_initializer=initializer))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512, kernel_initializer=initializer, bias_initializer=initializer))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(10, kernel_initializer=initializer, bias_initializer=initializer))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        " \n",
        "\n",
        "# training\n",
        "history = model.fit(X_train, Y_train,\n",
        "                        batch_size=128,\n",
        "                        nb_epoch=5,\n",
        "                        verbose=1,\n",
        "                        validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Duh3uniqEJOr",
        "colab_type": "text"
      },
      "source": [
        "#Orthogonal\n",
        "keras.initializers.Orthogonal(gain=1.0, seed=None)\n",
        "Initializer that generates a random orthogonal matrix.\n",
        "\n",
        "Arguments\n",
        "\n",
        "1. gain: Multiplicative factor to apply to the orthogonal matrix.\n",
        "2. seed: A Python integer. Used to seed the random generator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heR04DCHEbx0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import packages\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "#import dataset\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "#change shape from image to vector\n",
        "X_train = X_train.reshape(50000, 32 * 32 * 3)\n",
        "X_test = X_test.reshape(10000, 32 * 32 * 3)\n",
        "\n",
        "#preprocess\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255.0\n",
        "X_test /= 255.0\n",
        "\n",
        "#change labels from numeric to one hot encoded\n",
        "Y_train = to_categorical(y_train, 10)\n",
        "Y_test =  to_categorical(y_test, 10)\n",
        "\n",
        "#Model building\n",
        "initializer = keras.initializers.Orthogonal(gain=2.0, seed=None)\n",
        "model = Sequential()\n",
        "model.add(Dense(1024, input_shape=(3072,), kernel_initializer=initializer))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512, kernel_initializer=initializer))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512, kernel_initializer=initializer))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(10, kernel_initializer=initializer))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        " \n",
        "\n",
        "# training\n",
        "history = model.fit(X_train, Y_train,\n",
        "                        batch_size=128,\n",
        "                        nb_epoch=5,\n",
        "                        verbose=1,\n",
        "                        validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mluQA2hhMdla",
        "colab_type": "text"
      },
      "source": [
        "#Identity\n",
        "\n",
        "1. keras.initializers.Identity(gain=1.0)\n",
        "2. Initializer that generates the identity matrix.\n",
        "\n",
        "Only use for 2D matrices. If the desired matrix is not square, it gets padded with zeros for the additional rows/columns.\n",
        "\n",
        "Arguments\n",
        "\n",
        "1. gain: Multiplicative factor to apply to the identity matrix.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fb69AfQNErUX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import packages\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "#import dataset\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "#change shape from image to vector\n",
        "X_train = X_train.reshape(50000, 32 * 32 * 3)\n",
        "X_test = X_test.reshape(10000, 32 * 32 * 3)\n",
        "\n",
        "#preprocess\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255.0\n",
        "X_test /= 255.0\n",
        "\n",
        "#change labels from numeric to one hot encoded\n",
        "Y_train = to_categorical(y_train, 10)\n",
        "Y_test =  to_categorical(y_test, 10)\n",
        "\n",
        "#Model building\n",
        "initializer = keras.initializers.Identity(gain=1.0)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(1024, input_shape=(3072,), kernel_initializer=initializer))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512, kernel_initializer=initializer))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512, kernel_initializer=initializer))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(10, kernel_initializer=initializer))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        " \n",
        "\n",
        "# training\n",
        "history = model.fit(X_train, Y_train,\n",
        "                        batch_size=128,\n",
        "                        nb_epoch=5,\n",
        "                        verbose=1,\n",
        "                        validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqQYkh0MMxGM",
        "colab_type": "text"
      },
      "source": [
        "#lecun_uniform\n",
        "keras.initializers.lecun_uniform(seed=None)\n",
        "\n",
        "LeCun uniform initializer.\n",
        "\n",
        "It draws samples from a uniform distribution within [-limit, limit] where limit is sqrt(3 / fan_in) where fan_in is the number of input units in the weight tensor.\n",
        "\n",
        "Arguments\n",
        "\n",
        "1. seed: A Python integer. Used to seed the random generator.\n",
        "\n",
        "Returns\n",
        "\n",
        "1. An initializer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZn_tD8mM7bT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import packages\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "#import dataset\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "#change shape from image to vector\n",
        "X_train = X_train.reshape(50000, 32 * 32 * 3)\n",
        "X_test = X_test.reshape(10000, 32 * 32 * 3)\n",
        "\n",
        "#preprocess\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255.0\n",
        "X_test /= 255.0\n",
        "\n",
        "#change labels from numeric to one hot encoded\n",
        "Y_train = to_categorical(y_train, 10)\n",
        "Y_test =  to_categorical(y_test, 10)\n",
        "\n",
        "#Model building\n",
        "initializer = keras.initializers.lecun_uniform(seed=None)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(1024, input_shape=(3072,), kernel_initializer=initializer, bias_initializer=initializer))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512, kernel_initializer=initializer, bias_initializer=initializer))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512, kernel_initializer=initializer, bias_initializer=initializer))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(10, kernel_initializer=initializer, bias_initializer=initializer))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        " \n",
        "\n",
        "# training\n",
        "history = model.fit(X_train, Y_train,\n",
        "                        batch_size=128,\n",
        "                        nb_epoch=5,\n",
        "                        verbose=1,\n",
        "                        validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_5CNXt8NG7q",
        "colab_type": "text"
      },
      "source": [
        "#glorot_normal\n",
        "\n",
        "keras.initializers.glorot_normal(seed=None)\n",
        "\n",
        "Glorot normal initializer, also called Xavier normal initializer.\n",
        "\n",
        "It draws samples from a truncated normal distribution centered on 0 with stddev = sqrt(2 / (fan_in + fan_out)) where fan_in is the number of input units in the weight tensor and fan_out is the number of output units in the weight tensor.\n",
        "\n",
        "Arguments\n",
        "\n",
        "1. seed: A Python integer. Used to seed the random generator.\n",
        "\n",
        "Returns\n",
        "\n",
        "1. An initializer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxGxYIQBNZP8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import packages\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "#import dataset\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "#change shape from image to vector\n",
        "X_train = X_train.reshape(50000, 32 * 32 * 3)\n",
        "X_test = X_test.reshape(10000, 32 * 32 * 3)\n",
        "\n",
        "#preprocess\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255.0\n",
        "X_test /= 255.0\n",
        "\n",
        "#change labels from numeric to one hot encoded\n",
        "Y_train = to_categorical(y_train, 10)\n",
        "Y_test =  to_categorical(y_test, 10)\n",
        "\n",
        "#Model building\n",
        "initializer = keras.initializers.glorot_normal(seed=None)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(1024, input_shape=(3072,), kernel_initializer=initializer, bias_initializer=initializer))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512, kernel_initializer=initializer, bias_initializer=initializer))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512, kernel_initializer=initializer, bias_initializer=initializer))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(10, kernel_initializer=initializer, bias_initializer=initializer))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        " \n",
        "\n",
        "# training\n",
        "history = model.fit(X_train, Y_train,\n",
        "                        batch_size=128,\n",
        "                        nb_epoch=5,\n",
        "                        verbose=1,\n",
        "                        validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V53RcodcNmbd",
        "colab_type": "text"
      },
      "source": [
        "#glorot_uniform\n",
        "\n",
        "keras.initializers.glorot_uniform(seed=None)\n",
        "\n",
        "Glorot uniform initializer, also called Xavier uniform initializer.\n",
        "\n",
        "It draws samples from a uniform distribution within [-limit, limit] where limit is sqrt(6 / (fan_in + fan_out)) where fan_in is the number of input units in the weight tensor and fan_out is the number of output units in the weight tensor.\n",
        "\n",
        "Arguments\n",
        "\n",
        "1. seed: A Python integer. Used to seed the random generator.\n",
        "\n",
        "Returns\n",
        "\n",
        "1. An initializer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsVWfqeQNtxl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import packages\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "#import dataset\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "#change shape from image to vector\n",
        "X_train = X_train.reshape(50000, 32 * 32 * 3)\n",
        "X_test = X_test.reshape(10000, 32 * 32 * 3)\n",
        "\n",
        "#preprocess\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255.0\n",
        "X_test /= 255.0\n",
        "\n",
        "#change labels from numeric to one hot encoded\n",
        "Y_train = to_categorical(y_train, 10)\n",
        "Y_test =  to_categorical(y_test, 10)\n",
        "\n",
        "#Model building\n",
        "initializer = keras.initializers.glorot_uniform(seed=None)\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(1024, input_shape=(3072,), kernel_initializer=initializer, bias_initializer=initializer))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512, kernel_initializer=initializer, bias_initializer=initializer))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512, kernel_initializer=initializer, bias_initializer=initializer))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(10, kernel_initializer=initializer, bias_initializer=initializer))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        " \n",
        "\n",
        "# training\n",
        "history = model.fit(X_train, Y_train,\n",
        "                        batch_size=128,\n",
        "                        nb_epoch=5,\n",
        "                        verbose=1,\n",
        "                        validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1F2aV9rJN0Ez",
        "colab_type": "text"
      },
      "source": [
        "#he_normal\n",
        "\n",
        "keras.initializers.he_normal(seed=None)\n",
        "\n",
        "He normal initializer.\n",
        "\n",
        "It draws samples from a truncated normal distribution centered on 0 with stddev = sqrt(2 / fan_in) where fan_in is the number of input units in the weight tensor.\n",
        "\n",
        "Arguments\n",
        "\n",
        "1. seed: A Python integer. Used to seed the random generator.\n",
        "\n",
        "Returns\n",
        "\n",
        "An initializer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUZJTErrN5nc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import packages\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "#import dataset\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "#change shape from image to vector\n",
        "X_train = X_train.reshape(50000, 32 * 32 * 3)\n",
        "X_test = X_test.reshape(10000, 32 * 32 * 3)\n",
        "\n",
        "#preprocess\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255.0\n",
        "X_test /= 255.0\n",
        "\n",
        "#change labels from numeric to one hot encoded\n",
        "Y_train = to_categorical(y_train, 10)\n",
        "Y_test =  to_categorical(y_test, 10)\n",
        "\n",
        "#Model building\n",
        "initializer = keras.initializers.he_normal(seed=None)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(1024, input_shape=(3072,), kernel_initializer=initializer, bias_initializer=initializer))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512, kernel_initializer=initializer, bias_initializer=initializer))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512, kernel_initializer=initializer, bias_initializer=initializer))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(10, kernel_initializer=initializer, bias_initializer=initializer))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        " \n",
        "\n",
        "# training\n",
        "history = model.fit(X_train, Y_train,\n",
        "                        batch_size=128,\n",
        "                        nb_epoch=5,\n",
        "                        verbose=1,\n",
        "                        validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fjTgQ2-N6SU",
        "colab_type": "text"
      },
      "source": [
        "#lecun_normal\n",
        "\n",
        "keras.initializers.lecun_normal(seed=None)\n",
        "\n",
        "LeCun normal initializer.\n",
        "\n",
        "It draws samples from a truncated normal distribution centered on 0 with stddev = sqrt(1 / fan_in) where fan_in is the number of input units in the weight tensor.\n",
        "\n",
        "Arguments\n",
        "\n",
        "1. seed: A Python integer. Used to seed the random generator.\n",
        "\n",
        "Returns\n",
        "\n",
        "1. An initializer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lB14_Gl7N6rA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import packages\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "#import dataset\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "#change shape from image to vector\n",
        "X_train = X_train.reshape(50000, 32 * 32 * 3)\n",
        "X_test = X_test.reshape(10000, 32 * 32 * 3)\n",
        "\n",
        "#preprocess\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255.0\n",
        "X_test /= 255.0\n",
        "\n",
        "#change labels from numeric to one hot encoded\n",
        "Y_train = to_categorical(y_train, 10)\n",
        "Y_test =  to_categorical(y_test, 10)\n",
        "\n",
        "#Model building\n",
        "initializer = keras.initializers.lecun_normal(seed=None)\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(1024, input_shape=(3072,), kernel_initializer=initializer, bias_initializer=initializer))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512, kernel_initializer=initializer, bias_initializer=initializer))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512, kernel_initializer=initializer, bias_initializer=initializer))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(10, kernel_initializer=initializer, bias_initializer=initializer))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        " \n",
        "\n",
        "# training\n",
        "history = model.fit(X_train, Y_train,\n",
        "                        batch_size=128,\n",
        "                        nb_epoch=5,\n",
        "                        verbose=1,\n",
        "                        validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqMGiXtHN7Ba",
        "colab_type": "text"
      },
      "source": [
        "#he_uniform\n",
        "\n",
        "keras.initializers.he_uniform(seed=None)\n",
        "\n",
        "He uniform variance scaling initializer.\n",
        "\n",
        "It draws samples from a uniform distribution within [-limit, limit] where limit is sqrt(6 / fan_in) where fan_in is the number of input units in the weight tensor.\n",
        "\n",
        "Arguments\n",
        "\n",
        "1. seed: A Python integer. Used to seed the random generator.\n",
        "\n",
        "Returns\n",
        "\n",
        "An initializer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60P1yxX6N7PU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import packages\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "#import dataset\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "#change shape from image to vector\n",
        "X_train = X_train.reshape(50000, 32 * 32 * 3)\n",
        "X_test = X_test.reshape(10000, 32 * 32 * 3)\n",
        "\n",
        "#preprocess\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255.0\n",
        "X_test /= 255.0\n",
        "\n",
        "#change labels from numeric to one hot encoded\n",
        "Y_train = to_categorical(y_train, 10)\n",
        "Y_test =  to_categorical(y_test, 10)\n",
        "\n",
        "#Model building\n",
        "initializer = keras.initializers.he_uniform(seed=None)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(1024, input_shape=(3072,), kernel_initializer=initializer, bias_initializer=initializer))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512, kernel_initializer=initializer, bias_initializer=initializer))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512, kernel_initializer=initializer, bias_initializer=initializer))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(10, kernel_initializer=initializer, bias_initializer=initializer))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        " \n",
        "\n",
        "# training\n",
        "history = model.fit(X_train, Y_train,\n",
        "                        batch_size=128,\n",
        "                        nb_epoch=5,\n",
        "                        verbose=1,\n",
        "                        validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHHeipq8N7oE",
        "colab_type": "text"
      },
      "source": [
        "#Thank you for completing this notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFfwm0DZcOow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMM4hWrMcTJ9",
        "colab_type": "text"
      },
      "source": [
        "# ***LAB 3 BEGINS***\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atdfvoY1cOsS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2MjJI_kBDYy",
        "colab_type": "text"
      },
      "source": [
        "#Usage of optimizers\n",
        "\n",
        "An optimizer is one of the two arguments required for compiling a Keras model:\n",
        "\n",
        "The optimizer is provided in model compilation step as shown below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZZLzy1xA0TB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras import models\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import mnist\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from IPython.display import SVG\n",
        "\n",
        "NUM_ROWS = 28\n",
        "NUM_COLS = 28\n",
        "NUM_CLASSES = 10\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 10\n",
        "\n",
        "# Load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "\n",
        "\n",
        "# Reshape data\n",
        "X_train = X_train.reshape((X_train.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.reshape((X_test.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_test = X_test.astype('float32') / 255\n",
        "\n",
        "# Categorically encode labels\n",
        "y_train = to_categorical(y_train, NUM_CLASSES)\n",
        "y_test = to_categorical(y_test, NUM_CLASSES)\n",
        "\n",
        "\n",
        "# Build neural network\n",
        "model = models.Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(NUM_ROWS * NUM_COLS,)))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljnd23JDCKKT",
        "colab_type": "text"
      },
      "source": [
        "#Parameters common to all Keras optimizers\n",
        "\n",
        "The parameters clipnorm and clipvalue can be used with all optimizers to control gradient clipping:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hG0HTz9lCY5s",
        "colab_type": "text"
      },
      "source": [
        "#SGD\n",
        "\n",
        "keras.optimizers.SGD(learning_rate=0.01, momentum=0.0, nesterov=False)\n",
        "\n",
        "##Stochastic gradient descent optimizer.\n",
        "\n",
        "Includes support for momentum, learning rate decay, and Nesterov momentum.\n",
        "\n",
        "##Arguments\n",
        "\n",
        "1. learning_rate: float >= 0. Learning rate.\n",
        "2. momentum: float >= 0. Parameter that accelerates SGD in the relevant direction and dampens oscillations.\n",
        "3. nesterov: boolean. Whether to apply Nesterov momentum."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88yumcFOCVkM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "sgd=keras.optimizers.SGD(lr=0.01, momentum=0.0, nesterov=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RdoZtUVCnde",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=sgd,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aO8vbsw7ENqL",
        "colab_type": "text"
      },
      "source": [
        "#RMSprop\n",
        "\n",
        "keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9)\n",
        "\n",
        "##RMSProp optimizer.\n",
        "\n",
        "It is recommended to leave the parameters of this optimizer at their default values (except the learning rate, which can be freely tuned).\n",
        "\n",
        "Arguments\n",
        "\n",
        "1. learning_rate: float >= 0. Learning rate.\n",
        "2. rho: float >= 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IR-QUUrDEj0o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "rms=keras.optimizers.RMSprop(lr=0.001, rho=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lk6hNp3DEn-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=rms,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qx-VvwfIEy5w",
        "colab_type": "text"
      },
      "source": [
        "#Adagrad\n",
        "\n",
        "keras.optimizers.Adagrad(learning_rate=0.01)\n",
        "\n",
        "##Adagrad optimizer.\n",
        "\n",
        "Adagrad is an optimizer with parameter-specific learning rates, which are adapted relative to how frequently a parameter gets updated during training. The more updates a parameter receives, the smaller the learning rate.\n",
        "\n",
        "It is recommended to leave the parameters of this optimizer at their default values.\n",
        "\n",
        "##Arguments\n",
        "\n",
        "1. learning_rate: float >= 0. Initial learning rate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WjeweM7E5rL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "ada=keras.optimizers.Adagrad(lr=0.01)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIHdU-GnE6or",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=ada,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8ubIHPIFLEA",
        "colab_type": "text"
      },
      "source": [
        "#Adadelta\n",
        "\n",
        "keras.optimizers.Adadelta(learning_rate=1.0, rho=0.95)\n",
        "\n",
        "##Adadelta optimizer.\n",
        "\n",
        "Adadelta is a more robust extension of Adagrad that adapts learning rates based on a moving window of gradient updates, instead of accumulating all past gradients. This way, Adadelta continues learning even when many updates have been done. Compared to Adagrad, in the original version of Adadelta you don't have to set an initial learning rate. In this version, initial learning rate and decay factor can be set, as in most other Keras optimizers.\n",
        "\n",
        "It is recommended to leave the parameters of this optimizer at their default values.\n",
        "\n",
        "##Arguments\n",
        "\n",
        "1. learning_rate: float >= 0. Initial learning rate, defaults to 1. It is recommended to leave it at the default value.\n",
        "2. rho: float >= 0. Adadelta decay factor, corresponding to fraction of gradient to keep at each time step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhgBFpumFLWL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "adelta=keras.optimizers.Adadelta(lr=1.0, rho=0.95)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6FHDYGzFRP3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=adelta,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9L-CMG6Fdfh",
        "colab_type": "text"
      },
      "source": [
        "#Adam\n",
        "\n",
        "keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
        "\n",
        "##Adam optimizer.\n",
        "\n",
        "Default parameters follow those provided in the original paper.\n",
        "\n",
        "##Arguments\n",
        "\n",
        "1. learning_rate: float >= 0. Learning rate.\n",
        "2. beta_1: float, 0 < beta < 1. Generally close to 1.\n",
        "3. beta_2: float, 0 < beta < 1. Generally close to 1.\n",
        "4. amsgrad: boolean. Whether to apply the AMSGrad variant of this algorithm from the paper \"On the Convergence of Adam and Beyond\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJMOPew6FqqY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "adam=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPXdzhFZFq2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=adam,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cY_OJBuuF5Cx",
        "colab_type": "text"
      },
      "source": [
        "#Adamax\n",
        "\n",
        "keras.optimizers.Adamax(learning_rate=0.002, beta_1=0.9, beta_2=0.999)\n",
        "\n",
        "Adamax optimizer from Adam paper's Section 7.\n",
        "\n",
        "It is a variant of Adam based on the infinity norm. Default parameters follow those provided in the paper.\n",
        "\n",
        "##Arguments\n",
        "\n",
        "1. learning_rate: float >= 0. Learning rate.\n",
        "2. beta_1: float, 0 < beta < 1. Generally close to 1.\n",
        "3. beta_2: float, 0 < beta < 1. Generally close to 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gyPzlPZF_6g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "adamax=keras.optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6bN-BTcGABe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=adamax,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asUHZi1vGMt5",
        "colab_type": "text"
      },
      "source": [
        "#Nadam\n",
        "\n",
        "keras.optimizers.Nadam(learning_rate=0.002, beta_1=0.9, beta_2=0.999)\n",
        "\n",
        "##Nesterov Adam optimizer.\n",
        "\n",
        "Much like Adam is essentially RMSprop with momentum, Nadam is RMSprop with Nesterov momentum.\n",
        "\n",
        "Default parameters follow those provided in the paper. It is recommended to leave the parameters of this optimizer at their default values.\n",
        "\n",
        "##Arguments\n",
        "\n",
        "1. learning_rate: float >= 0. Learning rate.\n",
        "2. beta_1: float, 0 < beta < 1. Generally close to 1.\n",
        "3. beta_2: float, 0 < beta < 1. Generally close to 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNvmlsUnGTtb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "nadam=keras.optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qGcyfhNGUE8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=nadam,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UR2xxjsjGn8Q",
        "colab_type": "text"
      },
      "source": [
        "#Thank you for completing the notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnaiwqYkTxtF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n",
        "\n",
        "X_train = X_train.reshape(50000, 32 * 32 * 3)\n",
        "X_test = X_test.reshape(10000, 32 * 32 * 3)\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255.0\n",
        "X_test /= 255.0\n",
        "\n",
        "Y_train = to_categorical(Y_train, 10)\n",
        "Y_test =  to_categorical(Y_test, 10)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(1024, input_shape=(3072, )))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "from keras import optimizers\n",
        "adamax=keras.optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999)\n",
        "\n",
        "model.compile(optimizer=adamax,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, Y_test))\n",
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CU3zwwETyYp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras import models\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from IPython.display import SVG\n",
        "\n",
        "NUM_ROWS = 28\n",
        "NUM_COLS = 28\n",
        "NUM_CLASSES = 10\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 10\n",
        "\n",
        "(X_train, Y_train), (X_test, Y_test) = fashion_mnist.load_data()\n",
        "\n",
        "\n",
        "X_train = X_train.reshape((X_train.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.reshape((X_test.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_test = X_test.astype('float32') / 255\n",
        "\n",
        "Y_train = to_categorical(Y_train, NUM_CLASSES)\n",
        "Y_test = to_categorical(Y_test, NUM_CLASSES)\n",
        "\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(NUM_ROWS * NUM_COLS,)))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "from keras import optimizers\n",
        "adamax=keras.optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999)\n",
        "\n",
        "model.compile(optimizer=adamax,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, Y_test))\n",
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGHGTLmiT8QQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "iris_data = load_iris()\n",
        "\t\n",
        "x = iris_data.data\n",
        "y_ = iris_data.target.reshape(-1, 1) # Convert data to a single column\n",
        "\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "y = encoder.fit_transform(y_)\n",
        "\n",
        "\n",
        "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.01)\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(10, input_shape=(4,), activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "from keras import optimizers\n",
        "adamax=keras.optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999)\n",
        "\n",
        "model.compile(optimizer=adamax,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(train_x, train_y, verbose=2, batch_size=5, epochs=200)\n",
        "\n",
        "\n",
        "results = model.evaluate(test_x, test_y)\n",
        "\n",
        "print('Final test set loss: {:4f}'.format(results[0]))\n",
        "print('Final test set accuracy: {:4f}'.format(results[1]))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctJI0AhhX4uc",
        "colab_type": "text"
      },
      "source": [
        "**1) MNIST**\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "**Conclusion:** \n",
        "Among these the best accuracy we get is from Adamax but its test loss is not the least among all so with minimum test loss and high test accuracy we have Stochastic Gradient Descent perform the best."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5us22YOeYYNi",
        "colab_type": "text"
      },
      "source": [
        "**2) FASHION_MNIST**\n",
        "\n",
        "*Test Loss:* 0.327580436084270475 \n",
        "*Test Accuracy:* 0.889210\n",
        "\n",
        "**3) CIFAR 10**\n",
        "\n",
        "*Test Loss:* 1.4006804775238036 \n",
        "*Test Accuracy:* 0.61434\n",
        "\n",
        "**4) CIFAR 100**\n",
        "\n",
        "*Test Loss:* 3.6843630092620849\n",
        "*Test Accuracy:* 0.1624\n",
        "\n",
        "**5) IRIS**\n",
        "\n",
        "*Test Loss:* 0.003201 \n",
        "*Test Accuracy:* 1.000454203\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8mQwxTMY0BE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}